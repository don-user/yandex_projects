# ML_for_text_NLP

### Условия:
Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 
Необходимо подготовить и обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.
Метрики качества модели F1 не менее 0.75. 

Релаизация проекта с 2-мя решениями - с использованием нейронной сети BERT и без нее.

Описание данных:  
Данные находятся в файле /toxic_comments.csv  
text - содержит текст комментария,   
toxic — целевой признак.  

### Ход работы:
- Изучение данных
- Предобработка данных
- Анализ данных
- Подготовка данных для обучения с использованием TF-IDF
- Подготовка данных для обучения с сипользованием BERT
- Обучение моделей с помощью обработанных данных методом TF-IDF
- Обучение модели на выборке обработанной с помощью предобученной нейронной сетки BERT
- Обучение на сбалансированном классе целевого признака
- Тестирование лучшей модели

### Вывод:
В ходе исследовани было выявлено, то, что сбаласнированная выборка показывает более высоку оценку f1, как при импользовании метода TF-IDF, так и использования Bert.
Простая модель LogisticRegression, показала лйчший результат на валидационной выборкепри методе TF-IDF. Этот же решатель показал очень высокую оценку более 0,8 на данных обработанных с помощью нейронной модели Bert.
Можно сделать вывод, что предобученная модель Bert - toxic-bert, очень хорошо обучена на отзывах и хорошо разделяет отзывы на тксичные и не токсичные.
